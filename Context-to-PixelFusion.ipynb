{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9a112b-108e-4c7c-91d8-d014fdde0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804fcdd-4027-4455-af59-28a64a45a8cb",
   "metadata": {},
   "source": [
    "## MLFlow Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb1450b-1cf9-4a67-b9aa-210f9be6af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///home/user/MLFlow2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66046fbf-0f25-42e3-8b35-aa09a856bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"Context-to-PixelFusion\"\n",
    "\n",
    "try:\n",
    "    idExperiment = mlflow.create_experiment(experiment)\n",
    "except:\n",
    "    idExperiment = mlflow.get_experiment_by_name(experiment).experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93684e2b-1c1f-46cf-be10-f4ca11c76569",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc4b3cf-aaba-4609-8592-f537f78f8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(TP, TN, FP, FN):\n",
    "    \n",
    "    sensitivity = TP / (TP + FN)\n",
    "    \n",
    "    specificity = TN / (TN + FP)\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP+FN+FP+TN)\n",
    "    \n",
    "    recall= TP / (TP+FN)\n",
    "    \n",
    "    precision = TP/(TP + FP)\n",
    "    \n",
    "    baccuracy = (sensitivity + specificity) / 2\n",
    "    \n",
    "    IOU = TP / (TP + FP + FN)\n",
    "    \n",
    "    F1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "\n",
    "    metrics = {'iou': IOU, 'f1_score':F1_score,'accuracy':accuracy,'balanced_accuracy':baccuracy, 'precision': precision, 'recall': recall}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e25d5fa0-19e5-44da-8c1a-484537ed661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(input_path, filter_mask_path, groundtruth_path, output_path):\n",
    "    \n",
    "    print(input_path)\n",
    "    print(filter_mask_path)\n",
    "    tp = tn = fp = fn = 0\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    for filename in os.listdir(input_path):\n",
    "\n",
    "        mask = cv2.imread(os.path.join(input_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        groundtruth = cv2.imread(os.path.join(groundtruth_path, filename),cv2.IMREAD_GRAYSCALE)\n",
    "        groundtruth = cv2.dilate(groundtruth, kernel, iterations=1)\n",
    "\n",
    "        tn_temp, fp_temp, fn_temp, tp_temp = confusion_matrix(groundtruth.flatten(), mask.flatten()).ravel()\n",
    "\n",
    "        tp += tp_temp\n",
    "        tn += tn_temp\n",
    "        fp += fp_temp\n",
    "        fn += fn_temp\n",
    "\n",
    "    metrics = calculate_metrics(tp, tn, fp, fn)\n",
    "\n",
    "    ################ Apply Filter of Model Classification ################\n",
    "    tp = tn = fp = fn = 0\n",
    "    \n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    for filename in os.listdir(input_path):\n",
    "\n",
    "        mask = cv2.imread(os.path.join(input_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        groundtruth = cv2.imread(os.path.join(groundtruth_path, filename),cv2.IMREAD_GRAYSCALE)\n",
    "        groundtruth = cv2.dilate(groundtruth, kernel, iterations=1)\n",
    "        mask_filter = cv2.imread(os.path.join(filter_mask_path, \"mask/\"+filename), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        print(mask.shape)\n",
    "        print(mask_filter.shape)\n",
    "        mask_filtered = cv2.bitwise_and(mask, mask_filter)\n",
    "        cv2.imwrite(os.path.join(output_path, filename), mask_filtered)\n",
    "           \n",
    "        c_m = confusion_matrix(groundtruth.flatten(), mask_filtered.flatten(), labels = [0, 255])\n",
    "        '''if c_m.shape[0] == 1 and c_m.shape[1] == 1:\n",
    "            tn_temp, fp_temp, fn_temp, tp_temp = c_m.ravel()[0], 0 , 0 , 0\n",
    "        else:'''\n",
    "        tn_temp, fp_temp, fn_temp, tp_temp = c_m.ravel()\n",
    "\n",
    "        #tn_temp, fp_temp, fn_temp, tp_temp = np.float64(tn_temp), np.float64(fp_temp), np.float64(fn_temp), np.float64(tp_temp)\n",
    "\n",
    "        tp += tp_temp\n",
    "        tn += tn_temp\n",
    "        fp += fp_temp\n",
    "        fn += fn_temp\n",
    "\n",
    "    metrics_filtered = calculate_metrics(tp, tn, fp, fn)\n",
    "\n",
    "\n",
    "    with mlflow.start_run(experiment_id=idExperiment, run_name=input_path.split(\"/\")[1]+\"_\"+filter_mask_path.split(\"/\")[1]):\n",
    "        mlflow.log_param(\"MODEL_SEGMENTATION\", input_path.split(\"/\")[1])\n",
    "        mlflow.log_param(\"MODEL_CLASSIFICATION\", filter_mask_path.split(\"/\")[1])\n",
    "        print(metrics)\n",
    "        print(metrics_filtered)\n",
    "        #mlflow.log_artifact(\"/content/image_final.png\")\n",
    "        for key in metrics:\n",
    "            mlflow.log_metric(\"TEST_\"+key, metrics[key])\n",
    "        for key in metrics_filtered:\n",
    "            mlflow.log_metric(\"TEST_\"+key+\"_FILTERED\", metrics_filtered[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847efcd-d6af-4539-b68d-ea6e7ba04860",
   "metadata": {},
   "source": [
    "## Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bdb24fb-2c32-46c5-87b5-591beede4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR_PRE = \"./output/PRE/\"\n",
    "OUTPUT_DIR_CRI = \"./output/CRI/\"\n",
    "OUTPUT_DIR_CPF = \"./output/CPF/\"\n",
    "\n",
    "DATA_DIR = \"./amazonwildroadsdataset/\"\n",
    "groundtruth_path = os.path.join(DATA_DIR, \"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79074e85-373a-4221-a74a-7b0c6c633cdc",
   "metadata": {},
   "source": [
    "## Fusion and log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf28a53d-6cf7-4510-920f-45d543a096d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results_PRE = os.listdir(OUTPUT_DIR_PRE)\n",
    "list_results_CRI = os.listdir(OUTPUT_DIR_CRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "775e1e98-4989-466f-a20d-52a1f7c79171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_results_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51e469f4-d14b-47fc-a69f-2b354c8fd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUTPUT_DIR_CPF):\n",
    "    os.makedirs (OUTPUT_DIR_CPF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "580a59d9-4093-4468-b7a4-c9a8a2e3737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/PRE/UnetPlusPlus-timm-efficientnet-b7-imagenet-all_patches\n",
      "./output/CRI/resnet\n",
      "(1072, 2792)\n",
      "(1072, 2792)\n",
      "(1059, 2793)\n",
      "(1059, 2793)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2794)\n",
      "(1059, 2793)\n",
      "(1059, 2793)\n",
      "(1059, 2793)\n",
      "(1059, 2793)\n",
      "{'iou': 0.5317351010608061, 'f1_score': 0.6942912004726561, 'accuracy': 0.9930141079343066, 'balanced_accuracy': 0.8746774895156499, 'precision': 0.6434932303859159, 'recall': 0.7537966259341223}\n",
      "{'iou': 0.44933468551137146, 'f1_score': 0.6200564852318177, 'accuracy': 0.9924170216999415, 'balanced_accuracy': 0.7923412588885888, 'precision': 0.6558547841797399, 'recall': 0.5879638538760062}\n"
     ]
    }
   ],
   "source": [
    "for result_PRE in list_results_PRE:\n",
    "    for result_CRI in list_results_CRI:\n",
    "        output_join_path = os.path.join(OUTPUT_DIR_CPF, result_PRE+ \"_\"+ result_CRI)\n",
    "        input_path = os.path.join(OUTPUT_DIR_PRE, result_PRE)\n",
    "        \n",
    "        filter_mask_path = os.path.join(OUTPUT_DIR_CRI, result_CRI)\n",
    "        log_metrics(input_path, filter_mask_path, groundtruth_path, output_join_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386efbf-775b-4d19-b69c-55e21d4e3924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
